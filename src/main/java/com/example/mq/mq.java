package com.example.mq;

/**
 * Created by MintQ on 2018/5/30.
 *  消息队列 （Message Queue）        消息系统的核心作用就是三点：解耦，异步和并行。    好处： 解耦合、提高系统的响应时间。
 *      1、解耦合  ：场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。
 *                  传统模式的缺点：假如库存系统无法访问，则订单减库存将失败，从而导致订单失败，订单系统与库存系统耦合。
 *                  如何解决以上问题呢？引入应用消息队列后的方案.
 *                      订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功
 *                      库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作
 *                  假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。
 *      2、异步处理：场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种：串行的方式和并行方式。
 *                      串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户。
 *                      并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间。
 *                      假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。
 *                      因为CPU在单位时间内处理的请求数是一定的，假设CPU 1秒内吞吐量是100次。则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）。
 *                 小结：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？
 *                      引入消息队列，将不是必须的业务逻辑，异步处理。
 *                 按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20QPS。比串行提高了3倍，比并行提高了两倍！
 *      3、流量削锋：应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。
 *                          可以控制活动的人数，可以缓解短时间内高流量压垮应用。
 *                 用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。
 *                 秒杀业务根据消息队列中的请求信息，再做后续处理。
 *
 *
 *  消息队列分类： 1、点对点：消息生产者生产消息发送到queue中，然后 消息消费者从queue中取出并且消费消息。
 *               2、发布/订阅：消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。
 *
 *  Kafka 简介：Kafka是分布式发布-订阅的消息系统。它最初由Linkedln公司开发，使用Scala语言编写，之后成为Apache项目的一部分。
 *
 *  Kafka的特点：1、高吞吐量。
 *              2、可进行持久化操作。
 *              3、分布式系统，易于向外扩展。 所有的producer、broker和consumer都会有多个，均为分布式的。无需停机即可扩展机器。
 *              4、消息被处理的状态是在consumer端维护，而不是由server端维护。 当失败时能自动平衡。  （broker直管存消息和删消息，它是不维护消息状态的，它是无状态的！！）
 *              5、支持online和offline的场景。
 *
 *  Kafka的核心概念：1、Producer 特指消息的生产者
 *                 2、Consumer 特指消息的消费者
 *                 3、Consumer Group 消费者组，可以并行消费Topic中partition的消息
 *                 4、Broker ：每个kafka实例(server) / (缓存代理，Kafka集群中的一台或多台服务器统称为broker)。
 *                 5、topic : 特指Kafka处理的消息源（feeds of messages）的不同分类。
 *                 6、Partition ：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。
 *
 *                 7、Message ：消息，是通信的基本单位，每个producer可以向一个topic发布一些消息。
 *
 *
 * 《*》Kafka中关于 消息的“顺序消费”讨论：
 *      ~在说到消息中间件的时候，我们通常都会谈到一个特性：消息的顺序消费问题。这个问题看起来很简单：Producer发送消息1, 2, 3。。。 Consumer按1, 2, 3。。。顺序消费。
 *          但实际情况却是：无论RocketMQ，还是Kafka，缺省都不保证消息的严格有序消费！  这个特性看起来很简单，但为什么缺省他们都不保证呢？
 *
 *      1、“严格的顺序消费”有多么困难
 *              下面就从3个方面来分析一下，对于一个消息中间件来说，”严格的顺序消费”有多么困难，或者说不可能。
 *          ~发送端：发送端不能异步发送，异步发送在发送失败的情况下，就没办法保证消息顺序。
 *                  比如你连续发了1，2，3。 过了一会，返回结果1失败，2, 3成功。你把1再重新发送1遍，这个时候顺序就乱掉了。
 *          ~存储端：对于存储端，要保证消息顺序，会有以下几个问题：
 *                  （1）消息不能分区。也就是1个topic，只能有1个队列。在Kafka中，它叫做partition；在RocketMQ中，它叫做queue。 如果你有多个队列，那同1个topic的消息，会分散到多个分区里面，自然不能保证顺序。
 *                  （2）即使只有1个队列的情况下，会有第2个问题。该机器挂了之后，能否切换到其他机器？也就是高可用问题。
 *                      比如你当前的机器挂了，上面还有消息没有消费完。此时切换到其他机器，可用性保证了。但消息顺序就乱掉了。
 *                      要想保证，一方面要同步复制，不能异步复制；另1方面得保证，切机器之前，挂掉的机器上面，所有消息必须消费完了，不能有残留。很明显，这个很难！！！
 *          ~接收端：对于接收端，不能 并行消费，也即不能开多线程或者多个客户端消费同1个队列。
 *      2、总结：
 *          从上面的分析可以看出，要保证消息的严格有序，有多么困难！
 *          发送端和接收端的问题，还好解决一点，限制异步发送，限制并行消费。但对于存储端，机器挂了之后，切换的问题，就很难解决了。你切换了，可能消息就会乱；你不切换，那就暂时不可用。这2者之间，就需要权衡了。
 *
 *《*》消息中间件如何实现每秒几十万的高并发写入？ - Kafka  1、页缓存技术 + 磁盘顺序写；2、零拷贝技术
 *    1、页缓存技术 + 磁盘顺序写
 *      首先Kafka每次接收到数据都会往磁盘上去写，那么在这里我们不禁有一个疑问了，如果把数据基于磁盘来存储，频繁的往磁盘文件里写数据，这个性能会不会很差？大家肯定都觉得磁盘写性能是极差的。
 *      没错，要是真的跟上面那个图那么简单的话，那确实这个性能是比较差的。但是实际上Kafka在这里有极为优秀和出色的设计，
 *      就是为了保证数据写入性能，首先Kafka是`基于操作系统的页缓存`来实现文件写入的。 - 操作系统本身有一层缓存，叫做page cache，是在内存里的缓存，我们也可以称之为os cache，意思就是操作系统自己管理的缓存。
 *      所以大家就知道了，上面那个图里，Kafka在写数据的时候，(1)、一方面基于了os层面的page cache来写数据，所以性能很高，本质就是在写内存罢了。
 *                                                （2）、另外一个，他是采用`磁盘顺序写`的方式，所以即使数据刷入磁盘的时候，性能也是极高的，也跟写内存是差不多的。
 *    2、零拷贝技术
 *      大家应该都知道，从Kafka里我们经常要消费数据，那么消费的时候实际上就是要从kafka的磁盘文件里读取某条数据然后发送给下游的消费者，那么这里如果频繁的从磁盘读数据然后发给消费者，性能瓶颈在哪里呢？
 *      假设要是kafka什么优化都不做，就是很简单的从磁盘读数据发送给下游的消费者，那么大概过程如下所示：
 *          -先看看要读的数据在不在os cache里，如果不在的话就从磁盘文件里读取数据后放入os cache。
 *          -接着从操作系统的os cache里拷贝数据到应用程序进程的缓存里，再从应用程序进程的缓存里拷贝数据到操作系统层面的Socket缓存里，最后从Socket缓存里提取数据后发送到网卡，最后发送出去给下游消费。
 *      大家看上图，很明显可以看到有两次没必要的拷贝吧！ 一次是从操作系统的cache里拷贝到应用进程的缓存里，接着又从应用程序缓存里拷贝回操作系统的Socket缓存里。
 *      而且为了进行这两次拷贝，中间还发生了好几次上下文切换，一会儿是应用程序在执行，一会儿上下文切换到操作系统来执行。-所以这种方式来读取数据是比较消耗性能的。
 *      Kafka为了解决这个问题，在读数据的时候是引入零拷贝技术。
 *          也就是说，直接让操作系统的cache中的数据发送到网卡后传输给下游的消费者，中间跳过了两次拷贝数据的步骤，Socket缓存中仅仅会拷贝一个描述符过去，不会拷贝数据到Socket缓存。
 *          如果kafka集群经过良好的调优，大家会发现大量的数据都是直接写入os cache中，然后读数据的时候也是从os cache中读。相当于是Kafka完全基于内存提供数据的写和读了，所以这个整体性能会极其的高。
 *
 *
 */
public class mq {


}
